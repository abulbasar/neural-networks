{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "from keras import Sequential\n",
    "from keras.layers import LSTM,Dense,Dropout, Embedding, Conv1D, MaxPooling1D, Flatten\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "      <th>name</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i went and saw this movie last night after bei...</td>\n",
       "      <td>test</td>\n",
       "      <td>0_10.txt</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>actor turned director bill paxton follows up h...</td>\n",
       "      <td>test</td>\n",
       "      <td>10000_7.txt</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>as a recreational golfer with some knowledge o...</td>\n",
       "      <td>test</td>\n",
       "      <td>10001_9.txt</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i saw this film in a sneak preview and it is d...</td>\n",
       "      <td>test</td>\n",
       "      <td>10002_8.txt</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bill paxton has taken the true story of the 19...</td>\n",
       "      <td>test</td>\n",
       "      <td>10003_8.txt</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content label         name  \\\n",
       "0  i went and saw this movie last night after bei...  test     0_10.txt   \n",
       "1  actor turned director bill paxton follows up h...  test  10000_7.txt   \n",
       "2  as a recreational golfer with some knowledge o...  test  10001_9.txt   \n",
       "3  i saw this film in a sneak preview and it is d...  test  10002_8.txt   \n",
       "4  bill paxton has taken the true story of the 19...  test  10003_8.txt   \n",
       "\n",
       "  sentiment  \n",
       "0       pos  \n",
       "1       pos  \n",
       "2       pos  \n",
       "3       pos  \n",
       "4       pos  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_imdb(path):\n",
    "    from bs4 import BeautifulSoup\n",
    "    import re, json\n",
    "    import pandas as pd\n",
    "    \n",
    "    def preprocess(text):\n",
    "        text = BeautifulSoup(text.lower(), \"html5lib\").text #removed html tags\n",
    "        text = re.sub(r\"[\\W]+\", \" \", text)\n",
    "        return text\n",
    "    \n",
    "    with open(path, \"r\", encoding=\"utf8\") as f:\n",
    "        comments = pd.DataFrame.from_dict([json.loads(l) for l in f])\n",
    "        comments[\"content\"] = comments[\"content\"].apply(preprocess)\n",
    "        return comments\n",
    "        \n",
    "comments = load_imdb(\"/data/imdb-comments.json\")\n",
    "comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "      <th>name</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26829</th>\n",
       "      <td>i can give you four reasons to see this movie ...</td>\n",
       "      <td>train</td>\n",
       "      <td>11647_8.txt</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47053</th>\n",
       "      <td>polyester was the very first john water s film...</td>\n",
       "      <td>train</td>\n",
       "      <td>7349_1.txt</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28994</th>\n",
       "      <td>i really enjoyed the first episode and am look...</td>\n",
       "      <td>train</td>\n",
       "      <td>2345_9.txt</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41945</th>\n",
       "      <td>i hate to even waste the time it takes to writ...</td>\n",
       "      <td>train</td>\n",
       "      <td>2751_1.txt</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33300</th>\n",
       "      <td>throughly enjoy all the musical numbers each t...</td>\n",
       "      <td>train</td>\n",
       "      <td>6220_8.txt</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40100</th>\n",
       "      <td>transylvania 6 5000 is an insignificant but o...</td>\n",
       "      <td>train</td>\n",
       "      <td>12340_4.txt</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8860</th>\n",
       "      <td>flowers if it s one thing you ll take away fro...</td>\n",
       "      <td>test</td>\n",
       "      <td>6725_8.txt</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47551</th>\n",
       "      <td>this review is based on the dubbed shock o ram...</td>\n",
       "      <td>train</td>\n",
       "      <td>7798_1.txt</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31818</th>\n",
       "      <td>this has just been broadcast on bbc and i am a...</td>\n",
       "      <td>train</td>\n",
       "      <td>4888_8.txt</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11625</th>\n",
       "      <td>wow this was a great movie i just got it from ...</td>\n",
       "      <td>test</td>\n",
       "      <td>9213_10.txt</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content  label         name  \\\n",
       "26829  i can give you four reasons to see this movie ...  train  11647_8.txt   \n",
       "47053  polyester was the very first john water s film...  train   7349_1.txt   \n",
       "28994  i really enjoyed the first episode and am look...  train   2345_9.txt   \n",
       "41945  i hate to even waste the time it takes to writ...  train   2751_1.txt   \n",
       "33300  throughly enjoy all the musical numbers each t...  train   6220_8.txt   \n",
       "40100   transylvania 6 5000 is an insignificant but o...  train  12340_4.txt   \n",
       "8860   flowers if it s one thing you ll take away fro...   test   6725_8.txt   \n",
       "47551  this review is based on the dubbed shock o ram...  train   7798_1.txt   \n",
       "31818  this has just been broadcast on bbc and i am a...  train   4888_8.txt   \n",
       "11625  wow this was a great movie i just got it from ...   test  9213_10.txt   \n",
       "\n",
       "      sentiment  \n",
       "26829       pos  \n",
       "47053       neg  \n",
       "28994       pos  \n",
       "41945       neg  \n",
       "33300       pos  \n",
       "40100       neg  \n",
       "8860        pos  \n",
       "47551       neg  \n",
       "31818       pos  \n",
       "11625       pos  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.where(comments.sentiment == \"pos\", 1, 0)\n",
    "is_training = comments.label == \"train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(comments.content)\n",
    "doc_terms = tokenizer.texts_to_sequences(comments.content)\n",
    "len(doc_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i went and saw this movie last night after being coaxed to by a few friends of mine i ll admit that i was reluctant to see it because from what i knew of ashton kutcher he was only able to do comedy i was wrong kutcher played the character of jake fischer very well and kevin costner played ben randall with such professionalism the sign of a good movie is that it can toy with our emotions this one did exactly that the entire theater which was sold out was overcome by laughter during the first half of the movie and were moved to tears during the second half while exiting the theater i not only saw many women in tears but many full grown men as well trying desperately not to let anyone see them crying this movie was great and i suggest that you go see it before you judge '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.content[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 416, 2, 210, 10, 15, 238, 311, 100, 109, 28203, 5, 33, 3, 173, 352, 4, 1758, 9, 232, 975, 11, 9, 13, 5735, 5, 65, 7, 84, 37, 47, 9, 672, 4, 9942, 9315, 24, 13, 62, 477, 5, 78, 201, 9, 13, 356, 9315, 254, 1, 104, 4, 3373, 15901, 53, 69, 2, 1621, 7132, 254, 1155, 8399, 17, 139, 11306, 1, 2016, 4, 3, 49, 15, 6, 11, 7, 50, 2970, 17, 258, 1334, 10, 28, 117, 619, 11, 1, 442, 764, 61, 13, 2986, 43, 13, 3232, 33, 2142, 303, 1, 88, 304, 4, 1, 15, 2, 71, 1649, 5, 1716, 303, 1, 338, 304, 136, 11778, 1, 764, 9, 23, 62, 210, 107, 362, 8, 1716, 18, 107, 364, 2061, 339, 14, 69, 264, 2816, 23, 5, 276, 246, 65, 92, 2488, 10, 15, 13, 80, 2, 9, 1466, 11, 20, 141, 65, 7, 161, 20, 1671]\n"
     ]
    }
   ],
   "source": [
    "print(doc_terms[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"defaultdict(<class 'int'>, {'can': 19081, 'exactly': 1811, 'judge': 516, 'ashton': 49, 'character': 9551, 'night': 3415, 'see': 16263, 'in': 44006, 'after': 11359, 'what': 19837, 'but': 35787, 'anyone': 4749, 'not': 29780, 'and': 48298, 'jake': 158, 'only': 16467, 'from': 23240, 'laughter': 437, 'last': 4836, 'was': 32181, 'you': 27390, 'movie': 30562, 'women': 2531, 'second': 3352, 'moved': 619, 'saw': 5469, 'emotions': 749, 'before': 7146, 'entire': 2543, 'fischer': 21, 'costner': 58, 'many': \""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(tokenizer.word_docs)[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "words_by_index = dict([(i, word) for word, i in tokenizer.word_index.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'went', 'and', 'saw', 'this', 'movie', 'last', 'night', 'after', 'being', 'coaxed', 'to', 'by', 'a', 'few', 'friends', 'of', 'mine', 'i', 'll', 'admit', 'that', 'i', 'was', 'reluctant', 'to', 'see', 'it', 'because', 'from', 'what', 'i', 'knew', 'of', 'ashton', 'kutcher', 'he', 'was', 'only', 'able', 'to', 'do', 'comedy', 'i', 'was', 'wrong', 'kutcher', 'played', 'the', 'character', 'of', 'jake', 'fischer', 'very', 'well', 'and', 'kevin', 'costner', 'played', 'ben', 'randall', 'with', 'such', 'professionalism', 'the', 'sign', 'of', 'a', 'good', 'movie', 'is', 'that', 'it', 'can', 'toy', 'with', 'our', 'emotions', 'this', 'one', 'did', 'exactly', 'that', 'the', 'entire', 'theater', 'which', 'was', 'sold', 'out', 'was', 'overcome', 'by', 'laughter', 'during', 'the', 'first', 'half', 'of', 'the', 'movie', 'and', 'were', 'moved', 'to', 'tears', 'during', 'the', 'second', 'half', 'while', 'exiting', 'the', 'theater', 'i', 'not', 'only', 'saw', 'many', 'women', 'in', 'tears', 'but', 'many', 'full', 'grown', 'men', 'as', 'well', 'trying', 'desperately', 'not', 'to', 'let', 'anyone', 'see', 'them', 'crying', 'this', 'movie', 'was', 'great', 'and', 'i', 'suggest', 'that', 'you', 'go', 'see', 'it', 'before', 'you', 'judge']\n"
     ]
    }
   ],
   "source": [
    "print([words_by_index[t] for t in doc_terms[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103890"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xb2a11c7f0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series([len(r) for r in doc_terms]).plot.kde()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     9,   416,\n",
       "           2,   210,    10,    15,   238,   311,   100,   109, 28203,\n",
       "           5,    33,     3,   173,   352,     4,  1758,     9,   232,\n",
       "         975,    11,     9,    13,  5735,     5,    65,     7,    84,\n",
       "          37,    47,     9,   672,     4,  9942,  9315,    24,    13,\n",
       "          62,   477,     5,    78,   201,     9,    13,   356,  9315,\n",
       "         254,     1,   104,     4,  3373, 15901,    53,    69,     2,\n",
       "        1621,  7132,   254,  1155,  8399,    17,   139, 11306,     1,\n",
       "        2016,     4,     3,    49,    15,     6,    11,     7,    50,\n",
       "        2970,    17,   258,  1334,    10,    28,   117,   619,    11,\n",
       "           1,   442,   764,    61,    13,  2986,    43,    13,  3232,\n",
       "          33,  2142,   303,     1,    88,   304,     4,     1,    15,\n",
       "           2,    71,  1649,     5,  1716,   303,     1,   338,   304,\n",
       "         136, 11778,     1,   764,     9,    23,    62,   210,   107,\n",
       "         362,     8,  1716,    18,   107,   364,  2061,   339,    14,\n",
       "          69,   264,  2816,    23,     5,   276,   246,    65,    92,\n",
       "        2488,    10,    15,    13,    80,     2,     9,  1466,    11,\n",
       "          20,   141,    65,     7,   161,    20,  1671], dtype=int32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen = 250\n",
    "doc_terms_padded = pad_sequences(doc_terms, padding=\"pre\", maxlen=maxlen)\n",
    "doc_terms_padded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_16 (Embedding)     (None, 1000, 10)          10010     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 1000, 10)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 996, 64)           3264      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 249, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 247, 128)          24704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 61, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 400)               51600     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 401       \n",
      "=================================================================\n",
      "Total params: 221,563\n",
      "Trainable params: 221,563\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/100\n",
      "25000/25000 [==============================] - 45s 2ms/step - loss: 0.5383 - acc: 0.7220 - val_loss: 0.5674 - val_acc: 0.7222\n",
      "Epoch 2/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.4357 - acc: 0.7989 - val_loss: 0.4417 - val_acc: 0.7952\n",
      "Epoch 3/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.3981 - acc: 0.8207 - val_loss: 0.3798 - val_acc: 0.8375\n",
      "Epoch 4/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.3766 - acc: 0.8332 - val_loss: 0.3682 - val_acc: 0.8369\n",
      "Epoch 5/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.3637 - acc: 0.8396 - val_loss: 0.3776 - val_acc: 0.8393\n",
      "Epoch 6/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.3559 - acc: 0.8432 - val_loss: 0.3841 - val_acc: 0.8258\n",
      "Epoch 7/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.3455 - acc: 0.8490 - val_loss: 0.3552 - val_acc: 0.8407\n",
      "Epoch 8/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.3398 - acc: 0.8520 - val_loss: 0.4306 - val_acc: 0.8106\n",
      "Epoch 9/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.3353 - acc: 0.8551 - val_loss: 0.3669 - val_acc: 0.8364\n",
      "Epoch 10/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.3323 - acc: 0.8545 - val_loss: 0.4023 - val_acc: 0.8282\n",
      "Epoch 11/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.3283 - acc: 0.8571 - val_loss: 0.3530 - val_acc: 0.8473\n",
      "Epoch 12/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.3239 - acc: 0.8601 - val_loss: 0.3463 - val_acc: 0.8484\n",
      "Epoch 13/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.3229 - acc: 0.8619 - val_loss: 0.3553 - val_acc: 0.8474\n",
      "Epoch 14/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.3170 - acc: 0.8643 - val_loss: 0.3347 - val_acc: 0.8551\n",
      "Epoch 15/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.3180 - acc: 0.8626 - val_loss: 0.3354 - val_acc: 0.8542\n",
      "Epoch 16/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.3144 - acc: 0.8654 - val_loss: 0.3456 - val_acc: 0.8520\n",
      "Epoch 17/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.3126 - acc: 0.8654 - val_loss: 0.3317 - val_acc: 0.8542\n",
      "Epoch 18/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.3098 - acc: 0.8664 - val_loss: 0.3471 - val_acc: 0.8492\n",
      "Epoch 19/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.3105 - acc: 0.8654 - val_loss: 0.3568 - val_acc: 0.8480\n",
      "Epoch 20/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.3068 - acc: 0.8669 - val_loss: 0.3508 - val_acc: 0.8490\n",
      "Epoch 21/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.3081 - acc: 0.8665 - val_loss: 0.3750 - val_acc: 0.8367\n",
      "Epoch 22/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.3057 - acc: 0.8702 - val_loss: 0.3460 - val_acc: 0.8470\n",
      "Epoch 23/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.3042 - acc: 0.8709 - val_loss: 0.3401 - val_acc: 0.8521\n",
      "Epoch 24/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.3044 - acc: 0.8682 - val_loss: 0.3367 - val_acc: 0.8540\n",
      "Epoch 25/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.3011 - acc: 0.8722 - val_loss: 0.3530 - val_acc: 0.8500\n",
      "Epoch 26/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.3007 - acc: 0.8699 - val_loss: 0.3344 - val_acc: 0.8523\n",
      "Epoch 27/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.3007 - acc: 0.8717 - val_loss: 0.3561 - val_acc: 0.8490\n",
      "Epoch 28/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2996 - acc: 0.8710 - val_loss: 0.3473 - val_acc: 0.8521\n",
      "Epoch 29/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2999 - acc: 0.8715 - val_loss: 0.3407 - val_acc: 0.8519\n",
      "Epoch 30/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2970 - acc: 0.8734 - val_loss: 0.3410 - val_acc: 0.8530\n",
      "Epoch 31/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2977 - acc: 0.8728 - val_loss: 0.3666 - val_acc: 0.8385\n",
      "Epoch 32/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2933 - acc: 0.8756 - val_loss: 0.3465 - val_acc: 0.8492\n",
      "Epoch 33/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2956 - acc: 0.8717 - val_loss: 0.3837 - val_acc: 0.8319\n",
      "Epoch 34/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2968 - acc: 0.8704 - val_loss: 0.3486 - val_acc: 0.8531\n",
      "Epoch 35/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2943 - acc: 0.8720 - val_loss: 0.3520 - val_acc: 0.8466\n",
      "Epoch 36/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2885 - acc: 0.8772 - val_loss: 0.3552 - val_acc: 0.8525\n",
      "Epoch 37/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2888 - acc: 0.8768 - val_loss: 0.3511 - val_acc: 0.8484\n",
      "Epoch 38/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2887 - acc: 0.8750 - val_loss: 0.3653 - val_acc: 0.8508\n",
      "Epoch 39/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2864 - acc: 0.8778 - val_loss: 0.3668 - val_acc: 0.8448\n",
      "Epoch 40/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2866 - acc: 0.8777 - val_loss: 0.3481 - val_acc: 0.8486\n",
      "Epoch 41/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2863 - acc: 0.8784 - val_loss: 0.3878 - val_acc: 0.8408\n",
      "Epoch 42/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2882 - acc: 0.8757 - val_loss: 0.3539 - val_acc: 0.8465\n",
      "Epoch 43/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2874 - acc: 0.8782 - val_loss: 0.3463 - val_acc: 0.8504\n",
      "Epoch 44/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2890 - acc: 0.8761 - val_loss: 0.3566 - val_acc: 0.8464\n",
      "Epoch 45/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2877 - acc: 0.8745 - val_loss: 0.3516 - val_acc: 0.8499\n",
      "Epoch 46/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2853 - acc: 0.8767 - val_loss: 0.3437 - val_acc: 0.8526\n",
      "Epoch 47/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2868 - acc: 0.8766 - val_loss: 0.3506 - val_acc: 0.8492\n",
      "Epoch 48/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2822 - acc: 0.8786 - val_loss: 0.3716 - val_acc: 0.8444\n",
      "Epoch 49/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2855 - acc: 0.8779 - val_loss: 0.3565 - val_acc: 0.8447\n",
      "Epoch 50/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2831 - acc: 0.8779 - val_loss: 0.3643 - val_acc: 0.8450\n",
      "Epoch 51/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2851 - acc: 0.8771 - val_loss: 0.3571 - val_acc: 0.8460\n",
      "Epoch 52/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2891 - acc: 0.8736 - val_loss: 0.3660 - val_acc: 0.8468\n",
      "Epoch 53/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2848 - acc: 0.8784 - val_loss: 0.3521 - val_acc: 0.8458\n",
      "Epoch 54/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2862 - acc: 0.8764 - val_loss: 0.3492 - val_acc: 0.8470\n",
      "Epoch 55/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2806 - acc: 0.8778 - val_loss: 0.3698 - val_acc: 0.8484\n",
      "Epoch 56/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2837 - acc: 0.8772 - val_loss: 0.3573 - val_acc: 0.8487\n",
      "Epoch 57/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2850 - acc: 0.8764 - val_loss: 0.3631 - val_acc: 0.8468\n",
      "Epoch 58/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2897 - acc: 0.8751 - val_loss: 0.3551 - val_acc: 0.8450\n",
      "Epoch 59/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2880 - acc: 0.8759 - val_loss: 0.3676 - val_acc: 0.8422\n",
      "Epoch 60/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2849 - acc: 0.8777 - val_loss: 0.3682 - val_acc: 0.8470\n",
      "Epoch 61/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2794 - acc: 0.8808 - val_loss: 0.3543 - val_acc: 0.8459\n",
      "Epoch 62/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2792 - acc: 0.8786 - val_loss: 0.3768 - val_acc: 0.8478\n",
      "Epoch 63/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2816 - acc: 0.8782 - val_loss: 0.3825 - val_acc: 0.8453\n",
      "Epoch 64/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2825 - acc: 0.8786 - val_loss: 0.3643 - val_acc: 0.8460\n",
      "Epoch 65/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2786 - acc: 0.8807 - val_loss: 0.3633 - val_acc: 0.8470\n",
      "Epoch 66/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2790 - acc: 0.8799 - val_loss: 0.3764 - val_acc: 0.8423\n",
      "Epoch 67/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2800 - acc: 0.8794 - val_loss: 0.3678 - val_acc: 0.8484\n",
      "Epoch 68/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2777 - acc: 0.8780 - val_loss: 0.3762 - val_acc: 0.8396\n",
      "Epoch 69/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2770 - acc: 0.8798 - val_loss: 0.3574 - val_acc: 0.8478\n",
      "Epoch 70/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2762 - acc: 0.8809 - val_loss: 0.3987 - val_acc: 0.8438\n",
      "Epoch 71/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2800 - acc: 0.8798 - val_loss: 0.3667 - val_acc: 0.8470\n",
      "Epoch 72/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2767 - acc: 0.8793 - val_loss: 0.3773 - val_acc: 0.8405\n",
      "Epoch 73/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2712 - acc: 0.8841 - val_loss: 0.3591 - val_acc: 0.8453\n",
      "Epoch 74/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2766 - acc: 0.8819 - val_loss: 0.3683 - val_acc: 0.8462\n",
      "Epoch 75/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2762 - acc: 0.8837 - val_loss: 0.3700 - val_acc: 0.8438\n",
      "Epoch 76/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2759 - acc: 0.8800 - val_loss: 0.3787 - val_acc: 0.8429\n",
      "Epoch 77/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2723 - acc: 0.8850 - val_loss: 0.3797 - val_acc: 0.8420\n",
      "Epoch 78/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2772 - acc: 0.8816 - val_loss: 0.3709 - val_acc: 0.8426\n",
      "Epoch 79/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2819 - acc: 0.8768 - val_loss: 0.3829 - val_acc: 0.8439\n",
      "Epoch 80/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2779 - acc: 0.8788 - val_loss: 0.3735 - val_acc: 0.8422\n",
      "Epoch 81/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2885 - acc: 0.8716 - val_loss: 0.3656 - val_acc: 0.8414\n",
      "Epoch 82/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2820 - acc: 0.8775 - val_loss: 0.3705 - val_acc: 0.8432\n",
      "Epoch 83/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2804 - acc: 0.8782 - val_loss: 0.3728 - val_acc: 0.8384\n",
      "Epoch 84/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2780 - acc: 0.8814 - val_loss: 0.3772 - val_acc: 0.8423\n",
      "Epoch 85/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2780 - acc: 0.8800 - val_loss: 0.3684 - val_acc: 0.8416\n",
      "Epoch 86/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2748 - acc: 0.8826 - val_loss: 0.3758 - val_acc: 0.8412\n",
      "Epoch 87/100\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2804 - acc: 0.8782 - val_loss: 0.3962 - val_acc: 0.8380\n",
      "Epoch 88/100\n",
      " 3904/25000 [===>..........................] - ETA: 28s - loss: 0.2840 - acc: 0.8719"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(maxlen + 1, 10, input_length=maxlen))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(64, 5, activation='tanh'))\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "model.add(Conv1D(128, 3, activation='tanh'))\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(400, activation='tanh'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.fit(doc_terms_padded[is_training], y[is_training]\n",
    "          , validation_data=(doc_terms_padded[~is_training], y[~is_training])\n",
    "          , batch_size=64\n",
    "          , epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
