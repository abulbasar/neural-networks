{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "from keras import Sequential\n",
    "from keras.layers import LSTM,Dense,Dropout, Embedding, Conv1D, MaxPooling1D, Flatten\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "      <th>name</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i went and saw this movie last night after bei...</td>\n",
       "      <td>test</td>\n",
       "      <td>0_10.txt</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>actor turned director bill paxton follows up h...</td>\n",
       "      <td>test</td>\n",
       "      <td>10000_7.txt</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>as a recreational golfer with some knowledge o...</td>\n",
       "      <td>test</td>\n",
       "      <td>10001_9.txt</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i saw this film in a sneak preview and it is d...</td>\n",
       "      <td>test</td>\n",
       "      <td>10002_8.txt</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bill paxton has taken the true story of the 19...</td>\n",
       "      <td>test</td>\n",
       "      <td>10003_8.txt</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content label         name  \\\n",
       "0  i went and saw this movie last night after bei...  test     0_10.txt   \n",
       "1  actor turned director bill paxton follows up h...  test  10000_7.txt   \n",
       "2  as a recreational golfer with some knowledge o...  test  10001_9.txt   \n",
       "3  i saw this film in a sneak preview and it is d...  test  10002_8.txt   \n",
       "4  bill paxton has taken the true story of the 19...  test  10003_8.txt   \n",
       "\n",
       "  sentiment  \n",
       "0       pos  \n",
       "1       pos  \n",
       "2       pos  \n",
       "3       pos  \n",
       "4       pos  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_imdb(path):\n",
    "    from bs4 import BeautifulSoup\n",
    "    import re, json\n",
    "    import pandas as pd\n",
    "    \n",
    "    def preprocess(text):\n",
    "        text = BeautifulSoup(text.lower(), \"html5lib\").text #removed html tags\n",
    "        text = re.sub(r\"[\\W]+\", \" \", text)\n",
    "        return text\n",
    "    \n",
    "    with open(path, \"r\", encoding=\"utf8\") as f:\n",
    "        comments = pd.DataFrame.from_dict([json.loads(l) for l in f])\n",
    "        comments[\"content\"] = comments[\"content\"].apply(preprocess)\n",
    "        return comments\n",
    "        \n",
    "comments = load_imdb(\"/data/imdb-comments.json\")\n",
    "comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "      <th>name</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26829</th>\n",
       "      <td>i can give you four reasons to see this movie ...</td>\n",
       "      <td>train</td>\n",
       "      <td>11647_8.txt</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47053</th>\n",
       "      <td>polyester was the very first john water s film...</td>\n",
       "      <td>train</td>\n",
       "      <td>7349_1.txt</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28994</th>\n",
       "      <td>i really enjoyed the first episode and am look...</td>\n",
       "      <td>train</td>\n",
       "      <td>2345_9.txt</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41945</th>\n",
       "      <td>i hate to even waste the time it takes to writ...</td>\n",
       "      <td>train</td>\n",
       "      <td>2751_1.txt</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33300</th>\n",
       "      <td>throughly enjoy all the musical numbers each t...</td>\n",
       "      <td>train</td>\n",
       "      <td>6220_8.txt</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40100</th>\n",
       "      <td>transylvania 6 5000 is an insignificant but o...</td>\n",
       "      <td>train</td>\n",
       "      <td>12340_4.txt</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8860</th>\n",
       "      <td>flowers if it s one thing you ll take away fro...</td>\n",
       "      <td>test</td>\n",
       "      <td>6725_8.txt</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47551</th>\n",
       "      <td>this review is based on the dubbed shock o ram...</td>\n",
       "      <td>train</td>\n",
       "      <td>7798_1.txt</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31818</th>\n",
       "      <td>this has just been broadcast on bbc and i am a...</td>\n",
       "      <td>train</td>\n",
       "      <td>4888_8.txt</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11625</th>\n",
       "      <td>wow this was a great movie i just got it from ...</td>\n",
       "      <td>test</td>\n",
       "      <td>9213_10.txt</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content  label         name  \\\n",
       "26829  i can give you four reasons to see this movie ...  train  11647_8.txt   \n",
       "47053  polyester was the very first john water s film...  train   7349_1.txt   \n",
       "28994  i really enjoyed the first episode and am look...  train   2345_9.txt   \n",
       "41945  i hate to even waste the time it takes to writ...  train   2751_1.txt   \n",
       "33300  throughly enjoy all the musical numbers each t...  train   6220_8.txt   \n",
       "40100   transylvania 6 5000 is an insignificant but o...  train  12340_4.txt   \n",
       "8860   flowers if it s one thing you ll take away fro...   test   6725_8.txt   \n",
       "47551  this review is based on the dubbed shock o ram...  train   7798_1.txt   \n",
       "31818  this has just been broadcast on bbc and i am a...  train   4888_8.txt   \n",
       "11625  wow this was a great movie i just got it from ...   test  9213_10.txt   \n",
       "\n",
       "      sentiment  \n",
       "26829       pos  \n",
       "47053       neg  \n",
       "28994       pos  \n",
       "41945       neg  \n",
       "33300       pos  \n",
       "40100       neg  \n",
       "8860        pos  \n",
       "47551       neg  \n",
       "31818       pos  \n",
       "11625       pos  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.where(comments.sentiment == \"pos\", 1, 0)\n",
    "is_training = comments.label == \"train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 1250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=maxlen)\n",
    "tokenizer.fit_on_texts(comments.content)\n",
    "doc_terms = tokenizer.texts_to_sequences(comments.content)\n",
    "len(doc_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments.content[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(doc_terms[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "str(tokenizer.word_docs)[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "words_by_index = dict([(i, word) for word, i in tokenizer.word_index.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([words_by_index[t] for t in doc_terms[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.Series([len(r) for r in doc_terms]).plot.kde()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "doc_terms_padded = pad_sequences(doc_terms, maxlen=maxlen)\n",
    "doc_terms_padded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = doc_terms_padded[is_training]\n",
    "y_train = y[is_training]\n",
    "x_test = doc_terms_padded[~is_training]\n",
    "y_test = y[~is_training]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.set_random_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(maxlen, 10, input_length=maxlen))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(64, 5, activation='tanh'))\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "model.add(Conv1D(128, 3, activation='tanh'))\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(400, activation='tanh'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size=64, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
