{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulbasar/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/abulbasar/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "/Users/abulbasar/anaconda3/lib/python3.6/site-packages/sklearn/learning_curve.py:22: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n",
      "/Users/abulbasar/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import * \n",
    "pd.options.display.max_columns = 1000\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import * \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"/data/MNIST/mnist_train.csv\", header=None)\n",
    "df_test = pd.read_csv(\"/data/MNIST/mnist_test.csv\", header=None)\n",
    "\n",
    "X_train = (df_train.iloc[:, 1:].values/255).reshape(-1, 28, 28, 1) # width, height, channel\n",
    "X_test = (df_test.iloc[:, 1:].values/255).reshape(-1, 28, 28, 1)\n",
    "y_train = df_train.iloc[:, 0].values\n",
    "y_test = df_test.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28, 1), (10000, 28, 28, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               160100    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 180,438\n",
      "Trainable params: 180,438\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 67s 1ms/step - loss: 0.2939 - acc: 0.9073: 0s - loss: 0.2950 - acc:\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 72s 1ms/step - loss: 0.1213 - acc: 0.9614\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 68s 1ms/step - loss: 0.0981 - acc: 0.9694\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 67s 1ms/step - loss: 0.0867 - acc: 0.9729\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 58s 972us/step - loss: 0.0746 - acc: 0.9769\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0745 - acc: 0.9764: 1s - los\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 65s 1ms/step - loss: 0.0665 - acc: 0.9794: 3s - loss: 0.0667 - acc: 0 - ETA: 0s - loss: 0.0665\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 68s 1ms/step - loss: 0.0618 - acc: 0.9808: 0s - loss: 0.0615 -\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.0570 - acc: 0.9822\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 66s 1ms/step - loss: 0.0576 - acc: 0.9824\n",
      "10000/10000 [==============================] - 4s 415us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.022708933349730797, 0.9915]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_x = 28 * 28\n",
    "n_y = 10\n",
    "tf.set_random_seed(1)\n",
    "\n",
    "def build_model():\n",
    "    model = keras.Sequential()\n",
    "    model.add(Conv2D(filters=32, activation=\"relu\", kernel_size=(5, 5), input_shape = (28, 28, 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(filters=64, activation=\"relu\", kernel_size=(3, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(rate=0.8))\n",
    "    model.add(Dense(activation=\"relu\", units=100))\n",
    "    model.add(Dense(activation=\"softmax\", units=n_y))\n",
    "    \n",
    "    model.compile(loss=keras.losses.categorical_crossentropy\n",
    "                  , optimizer=\"adam\"\n",
    "                  , metrics = [\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()\n",
    "\n",
    "model.fit(x = X_train\n",
    "          , y = keras.utils.to_categorical(y_train)\n",
    "          , verbose = 1\n",
    "          , epochs = 10\n",
    "          , batch_size= 64)\n",
    "model.evaluate(X_test, keras.utils.to_categorical(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
