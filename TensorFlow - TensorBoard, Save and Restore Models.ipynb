{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulbasar/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mode (Y/F):Y\n",
      "Training mode: True\n"
     ]
    }
   ],
   "source": [
    "training_mode = input(\"Training mode (Y/F):\")\n",
    "training_mode = training_mode == \"Y\"\n",
    "print(\"Training mode:\", training_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "batch_size = 32\n",
    "ckpt_dir = \"/tmp/tensor_cp/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (10000, 784), (60000, 10), (10000, 10))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_mnist_csv(path = \"/data/MNIST/\", one_hot = False, shape = None):\n",
    "    import pandas as pd\n",
    "    df_train = pd.read_csv(path + \"mnist_train.csv\", header=None)\n",
    "    df_test = pd.read_csv(path + \"mnist_test.csv\", header=None)\n",
    "    \n",
    "    X_train = df_train.iloc[:, 1:].values/255\n",
    "    X_test = df_test.iloc[:, 1:].values/255\n",
    "    y_train = df_train.iloc[:, 0].values\n",
    "    y_test = df_test.iloc[:, 0].values\n",
    "    \n",
    "    if shape == \"3D\":\n",
    "        X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "        X_test = X_test.reshape(-1, 28, 28, 1)\n",
    "    \n",
    "    if one_hot:\n",
    "        eye = np.eye(10)\n",
    "        y_train, y_test = eye[y_train], eye[y_test]\n",
    "        \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = load_mnist_csv(one_hot=True)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(X, y, batch_size = 32, epochs = 1):\n",
    "    from collections import namedtuple\n",
    "    from math import ceil\n",
    "    Batch = namedtuple(\"batch\", [\"epoch\", \"global_step\", \"progress\", \"X_batch\", \"y_batch\"])\n",
    "    global_step = 0\n",
    "    for epoch in range(epochs):\n",
    "        m = X_train.shape[0]\n",
    "        indices = np.arange(m)\n",
    "        np.random.shuffle(indices)\n",
    "        X = X[indices]\n",
    "        y = y[indices]\n",
    "        num_batches = ceil(m/batch_size)\n",
    "        for j in range(num_batches):\n",
    "            start = j * batch_size\n",
    "            end = start + batch_size\n",
    "            X_batch = X[start:end]\n",
    "            y_batch = y[start:end]\n",
    "            progress = (j + 1) * 100 / num_batches\n",
    "            yield Batch(epoch, global_step, progress, X_batch, y_batch)\n",
    "            global_step = global_step + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the computation graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "graph = tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input to the computation graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(dtype=tf.float32, shape=(None, 784))\n",
    "y = tf.placeholder(dtype=tf.int32, shape=(None,10))\n",
    "dropout_rate = tf.placeholder_with_default(0.0, shape=())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build computation graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_img = tf.reshape(X, shape=(-1, 28, 28, 1))\n",
    "    \n",
    "layers = [\n",
    "    tf.layers.Conv2D(32, (5, 5), activation=tf.nn.relu),\n",
    "    tf.layers.MaxPooling2D((2, 2), (2, 2)),\n",
    "    tf.layers.Conv2D(64, (3, 3), activation=tf.nn.relu),\n",
    "    tf.layers.MaxPooling2D((2, 2), (2, 2)),\n",
    "    tf.layers.Flatten(),\n",
    "    tf.layers.Dropout(dropout_rate),\n",
    "    tf.layers.Dense(400, tf.nn.relu),\n",
    "    tf.layers.Dense(100, tf.nn.relu),\n",
    "    tf.layers.Dense(10, None)\n",
    "]\n",
    "logits = X_img\n",
    "for layer in layers:\n",
    "    logits = layer(logits)\n",
    "\n",
    "loss = tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=logits)\n",
    "cost = tf.reduce_mean(loss)\n",
    "\n",
    "tf.summary.scalar(\"cost\", cost)\n",
    "\n",
    "op = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n",
    "\n",
    "macthes = tf.equal(tf.argmax(y, axis=1), tf.argmax(logits, axis=1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(macthes, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a tensor saver object to save or restore the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'conv2d/kernel:0' shape=(5, 5, 1, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d/bias:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d_1/kernel:0' shape=(3, 3, 32, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d_1/bias:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'dense/kernel:0' shape=(1600, 400) dtype=float32_ref>,\n",
       " <tf.Variable 'dense/bias:0' shape=(400,) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_1/kernel:0' shape=(400, 100) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_1/bias:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_2/kernel:0' shape=(100, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_2/bias:0' shape=(10,) dtype=float32_ref>,\n",
       " <tf.Variable 'beta1_power:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'beta2_power:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d/kernel/Adam:0' shape=(5, 5, 1, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d/kernel/Adam_1:0' shape=(5, 5, 1, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d/bias/Adam:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d/bias/Adam_1:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d_1/kernel/Adam:0' shape=(3, 3, 32, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d_1/kernel/Adam_1:0' shape=(3, 3, 32, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d_1/bias/Adam:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d_1/bias/Adam_1:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'dense/kernel/Adam:0' shape=(1600, 400) dtype=float32_ref>,\n",
       " <tf.Variable 'dense/kernel/Adam_1:0' shape=(1600, 400) dtype=float32_ref>,\n",
       " <tf.Variable 'dense/bias/Adam:0' shape=(400,) dtype=float32_ref>,\n",
       " <tf.Variable 'dense/bias/Adam_1:0' shape=(400,) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_1/kernel/Adam:0' shape=(400, 100) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_1/kernel/Adam_1:0' shape=(400, 100) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_1/bias/Adam:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_1/bias/Adam_1:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_2/kernel/Adam:0' shape=(100, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_2/kernel/Adam_1:0' shape=(100, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_2/bias/Adam:0' shape=(10,) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_2/bias/Adam_1:0' shape=(10,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_collection(\"variables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create summary for the accuracy, input images and the kernel to show them in the tensorboard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.summary.scalar(\"accuracy\", accuracy)\n",
    "tf.summary.image(\"input_images\", X_img)\n",
    "for v in tf.global_variables():\n",
    "    if \"kernel\" in v.name:\n",
    "        tf.summary.histogram(v.name.replace(\":\", \"_\"), v)\n",
    "summary_agg = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run training, write the summary to tensorboard and save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, progress: 100, cost: 0.0115, acc: 1.0000\n",
      " validation accuracy: 0.9865\n",
      "[[-0.04012164 -0.10293753  0.01783721 -0.06238898  0.08442013 -0.06689017\n",
      "  -0.03600748  0.10734922 -0.12466065  0.04650401 -0.03229889  0.13118029\n",
      "  -0.01973842  0.06481586  0.09878534 -0.02696361  0.04368662 -0.07343274\n",
      "   0.08764903  0.02837615  0.00431452 -0.01515117  0.01117284  0.10848288\n",
      "  -0.06746104  0.0613336   0.07979139  0.16718565  0.0205169  -0.00472976\n",
      "  -0.12347219  0.07548217]]\n"
     ]
    }
   ],
   "source": [
    "if training_mode:\n",
    "    tf.set_random_seed(1)\n",
    "    np.random.seed(1)\n",
    "    \n",
    "    #Create a file write to write summary and graph to tensorboard\n",
    "    writer = tf.summary.FileWriter(logdir=\"/tmp/tensorboard/%d\" % time(), graph=tf.get_default_graph())\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for batch in data_generator(X_train, y_train, batch_size, epochs):\n",
    "            _, accuracy_, cost_, summary_ = sess.run([op, accuracy, cost, summary_agg]\n",
    "                                , feed_dict={X: batch.X_batch, y: batch.y_batch, dropout_rate: 0.8})\n",
    "            writer.add_summary(summary_, batch.global_step)\n",
    "            print(\"Epoch: %d, progress: %3d, cost: %.4f, acc: %.4f\" \n",
    "                  % (batch.epoch, batch.progress, cost_, accuracy_), end=\"\\r\")\n",
    "            \n",
    "            if batch.progress == 100:\n",
    "                acc = sess.run(accuracy, feed_dict={X: X_test, y: y_test})\n",
    "                print(\"\\n validation accuracy: %.4f\" % acc)\n",
    "\n",
    "        saver.save(sess, ckpt_dir)\n",
    "        print(sess.run(\"conv2d/kernel:0\")[0][0])\n",
    "else: \n",
    "    print(\"[Inferencing mode] No training is performed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/tensor_cp/\n",
      "\n",
      "validation accuracy: 0.9865\n",
      "\n",
      "conv2d/kernel:0\n",
      " [[-0.04012164 -0.10293753  0.01783721 -0.06238898  0.08442013 -0.06689017\n",
      "  -0.03600748  0.10734922 -0.12466065  0.04650401 -0.03229889  0.13118029\n",
      "  -0.01973842  0.06481586  0.09878534 -0.02696361  0.04368662 -0.07343274\n",
      "   0.08764903  0.02837615  0.00431452 -0.01515117  0.01117284  0.10848288\n",
      "  -0.06746104  0.0613336   0.07979139  0.16718565  0.0205169  -0.00472976\n",
      "  -0.12347219  0.07548217]]\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, ckpt_dir)\n",
    "    acc = sess.run(accuracy, feed_dict={X: X_test, y: y_test})\n",
    "    print(\"\\nvalidation accuracy: %.4f\" % acc)\n",
    "    print(\"\\nconv2d/kernel:0\\n\", sess.run(\"conv2d/kernel:0\")[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
