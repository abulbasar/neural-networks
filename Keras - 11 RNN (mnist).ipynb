{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "\n",
    "import math\n",
    "\n",
    "\n",
    "from os.path import expanduser\n",
    "home = expanduser(\"~\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (10000, 28, 28), (60000, 10), (10000, 10))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_mnist_csv(path, one_hot = False, shape = None):\n",
    "    df_train = pd.read_csv(path + \"mnist_train.csv\", header=None)\n",
    "    df_test = pd.read_csv(path + \"mnist_test.csv\", header=None)\n",
    "    \n",
    "    X_train = df_train.iloc[:, 1:].values/255.0\n",
    "    X_test = df_test.iloc[:, 1:].values/255.0\n",
    "    y_train = df_train.iloc[:, 0].values\n",
    "    y_test = df_test.iloc[:, 0].values\n",
    "    \n",
    "    if shape == \"2D\":\n",
    "        X_train = X_train.reshape(-1, 28, 28)\n",
    "        X_test = X_test.reshape(-1, 28, 28)\n",
    "    \n",
    "    if one_hot:\n",
    "        eye = np.eye(len(np.unique(y_train)))\n",
    "        y_train, y_test = eye[y_train], eye[y_test]\n",
    "        \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = load_mnist_csv(home + \"/data/MNIST/\", one_hot=True, shape = \"2D\")\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 28, 128)           80384     \n",
      "=================================================================\n",
      "Total params: 80,384\n",
      "Trainable params: 80,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 28, 128)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape = (28, 28)),\n",
    "    keras.layers.LSTM(units = 128, activation = \"tanh\", return_sequences=True)\n",
    "])\n",
    "model.summary()\n",
    "model.predict(X_train[:1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 128)               80384     \n",
      "=================================================================\n",
      "Total params: 80,384\n",
      "Trainable params: 80,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7febe8516560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 128)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# default value for return_sequences\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape = (28, 28)),\n",
    "    keras.layers.LSTM(units = 128, activation = \"tanh\", return_sequences=False) \n",
    "])\n",
    "model.summary()\n",
    "model.predict(X_train[:1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_27 (LSTM)               (None, 28, 128)           80384     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 28, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_28 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 229,770\n",
      "Trainable params: 229,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fec6a8375f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 10)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# default value for return_sequences\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape = (28, 28)),\n",
    "    keras.layers.LSTM(units = 128, activation = \"tanh\", return_sequences=True),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.LSTM(units = 128, activation = \"tanh\", return_sequences=False),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(units = 128, activation = \"relu\"),\n",
    "    keras.layers.Dense(units = 10, activation = \"softmax\")\n",
    "])\n",
    "model.summary()\n",
    "model.predict(X_train[:1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_41 (LSTM)               (None, 28, 128)           80384     \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 28, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_42 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 229,770\n",
      "Trainable params: 229,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 41s 43ms/step - loss: 0.3908 - accuracy: 0.8716 - val_loss: 0.1315 - val_accuracy: 0.9606\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 54s 57ms/step - loss: 0.1102 - accuracy: 0.9672 - val_loss: 0.0785 - val_accuracy: 0.9762\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 81s 86ms/step - loss: 0.0756 - accuracy: 0.9767 - val_loss: 0.0528 - val_accuracy: 0.9854\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 85s 91ms/step - loss: 0.0601 - accuracy: 0.9818 - val_loss: 0.0539 - val_accuracy: 0.9849\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 91s 97ms/step - loss: 0.0486 - accuracy: 0.9852 - val_loss: 0.0454 - val_accuracy: 0.9856\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 66s 70ms/step - loss: 0.0413 - accuracy: 0.9873 - val_loss: 0.0400 - val_accuracy: 0.9880\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 81s 86ms/step - loss: 0.0331 - accuracy: 0.9895 - val_loss: 0.0372 - val_accuracy: 0.9889\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 65s 69ms/step - loss: 0.0342 - accuracy: 0.9893 - val_loss: 0.0337 - val_accuracy: 0.9911\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 70s 74ms/step - loss: 0.0279 - accuracy: 0.9916 - val_loss: 0.0404 - val_accuracy: 0.9885\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 95s 101ms/step - loss: 0.0260 - accuracy: 0.9921 - val_loss: 0.0439 - val_accuracy: 0.9872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7febb607ef50>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape = (28, 28)),\n",
    "    keras.layers.LSTM(units = 128, activation = \"tanh\", return_sequences=True),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.LSTM(units = 128, activation = \"tanh\", return_sequences=False),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(units = 128, activation = \"relu\"),\n",
    "    keras.layers.Dense(units = 10, activation = \"softmax\")\n",
    "])\n",
    "model.summary()\n",
    "op = keras.optimizers.Adam(learning_rate=0.001, decay = 1e-5)\n",
    "model.compile(optimizer = op, \n",
    "              loss = keras.losses.categorical_crossentropy, \n",
    "              metrics = [\"accuracy\"])\n",
    "model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = 10, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
