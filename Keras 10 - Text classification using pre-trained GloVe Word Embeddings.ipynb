{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://keras.io/examples/nlp/pretrained_word_embeddings/\n",
    "    \n",
    "\n",
    "# Introduction\n",
    "In this example, we show how to train a text classification model that uses pre-trained word embeddings.\n",
    "\n",
    "We'll work with the Newsgroup20 dataset, a set of 20,000 message board messages belonging to 20 different topic categories.\n",
    "\n",
    "For the pre-trained word embeddings, we'll use GloVe embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pathlib\n",
    "\n",
    "from datetime import datetime\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Embedding, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embed a 1,000 word vocabulary into 5 dimensions.\n",
    "embedding_layer = tf.keras.layers.Embedding(1000, 5)\n",
    "a = embedding_layer(tf.constant(np.arange(0, 1000))).numpy()\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Group dataset\n",
    "\n",
    "The 20 Newsgroups data set is a collection of approximately 20,000 newsgroup documents, partitioned (nearly) evenly across 20 different newsgroups. To the best of my knowledge, it was originally collected by Ken Lang, probably for his Newsweeder: Learning to filter netnews paper, though he does not explicitly mention this collection. The 20 newsgroups collection has become a popular data set for experiments in text applications of machine learning techniques, such as text classification and text clustering.\n",
    "    \n",
    "The data is organized into 20 different newsgroups, each corresponding to a different topic. Some of the newsgroups are very closely related to each other (e.g. comp.sys.ibm.pc.hardware / comp.sys.mac.hardware), while others are highly unrelated (e.g misc.forsale / soc.religion.christian). Here is a list of the 20 newsgroups, partitioned (more or less) according to subject matter:\n",
    "\n",
    "http://qwone.com/~jason/20Newsgroups/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/abasar/.keras/datasets/20_newsgroup')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = keras.utils.get_file(\n",
    "    \"news20.tar.gz\",\n",
    "    \"http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.tar.gz\",\n",
    "    untar=True,\n",
    ")\n",
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\r\n",
      "drwxr-xr-x  1002 abasar  staff  32064 Apr 20  1998 \u001b[34malt.atheism\u001b[m\u001b[m\r\n",
      "drwxr-xr-x  1002 abasar  staff  32064 Apr 20  1998 \u001b[34mcomp.graphics\u001b[m\u001b[m\r\n",
      "drwxr-xr-x  1002 abasar  staff  32064 Apr 20  1998 \u001b[34mcomp.os.ms-windows.misc\u001b[m\u001b[m\r\n",
      "drwxr-xr-x  1002 abasar  staff  32064 Apr 20  1998 \u001b[34mcomp.sys.ibm.pc.hardware\u001b[m\u001b[m\r\n",
      "drwxr-xr-x  1002 abasar  staff  32064 Apr 20  1998 \u001b[34mcomp.sys.mac.hardware\u001b[m\u001b[m\r\n",
      "drwxr-xr-x  1002 abasar  staff  32064 Apr 20  1998 \u001b[34mcomp.windows.x\u001b[m\u001b[m\r\n",
      "drwxr-xr-x  1002 abasar  staff  32064 Apr 20  1998 \u001b[34mmisc.forsale\u001b[m\u001b[m\r\n",
      "drwxr-xr-x  1002 abasar  staff  32064 Apr 20  1998 \u001b[34mrec.autos\u001b[m\u001b[m\r\n",
      "drwxr-xr-x  1002 abasar  staff  32064 Apr 20  1998 \u001b[34mrec.motorcycles\u001b[m\u001b[m\r\n",
      "drwxr-xr-x  1002 abasar  staff  32064 Apr 20  1998 \u001b[34mrec.sport.baseball\u001b[m\u001b[m\r\n",
      "drwxr-xr-x  1002 abasar  staff  32064 Apr 20  1998 \u001b[34mrec.sport.hockey\u001b[m\u001b[m\r\n",
      "drwxr-xr-x  1002 abasar  staff  32064 Apr 20  1998 \u001b[34msci.crypt\u001b[m\u001b[m\r\n",
      "drwxr-xr-x  1002 abasar  staff  32064 Apr 20  1998 \u001b[34msci.electronics\u001b[m\u001b[m\r\n",
      "drwxr-xr-x  1002 abasar  staff  32064 Apr 20  1998 \u001b[34msci.med\u001b[m\u001b[m\r\n",
      "drwxr-xr-x  1002 abasar  staff  32064 Apr 20  1998 \u001b[34msci.space\u001b[m\u001b[m\r\n",
      "drwxr-xr-x   999 abasar  staff  31968 Apr 20  1998 \u001b[34msoc.religion.christian\u001b[m\u001b[m\r\n",
      "drwxr-xr-x  1002 abasar  staff  32064 Apr 20  1998 \u001b[34mtalk.politics.guns\u001b[m\u001b[m\r\n",
      "drwxr-xr-x  1002 abasar  staff  32064 Apr 20  1998 \u001b[34mtalk.politics.mideast\u001b[m\u001b[m\r\n",
      "drwxr-xr-x  1002 abasar  staff  32064 Apr 20  1998 \u001b[34mtalk.politics.misc\u001b[m\u001b[m\r\n",
      "drwxr-xr-x  1002 abasar  staff  32064 Apr 20  1998 \u001b[34mtalk.religion.misc\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l /Users/abasar/.keras/datasets/20_newsgroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of directories: 20\n",
      "Directory names: ['talk.politics.mideast', 'rec.autos', 'comp.sys.mac.hardware', 'alt.atheism', 'rec.sport.baseball', 'comp.os.ms-windows.misc', 'rec.sport.hockey', 'sci.crypt', 'sci.med', 'talk.politics.misc', 'rec.motorcycles', 'comp.windows.x', 'comp.graphics', 'comp.sys.ibm.pc.hardware', 'sci.electronics', 'talk.politics.guns', 'sci.space', 'soc.religion.christian', 'misc.forsale', 'talk.religion.misc']\n",
      "Number of files in comp.graphics: 1000\n",
      "Some example filenames: ['38254', '38402', '38630', '38865', '38891']\n"
     ]
    }
   ],
   "source": [
    "data_dir = pathlib.Path(data_path).parent / \"20_newsgroup\"\n",
    "dirnames = os.listdir(data_dir)\n",
    "print(\"Number of directories:\", len(dirnames))\n",
    "print(\"Directory names:\", dirnames)\n",
    "\n",
    "fnames = os.listdir(data_dir / \"comp.graphics\")\n",
    "print(\"Number of files in comp.graphics:\", len(fnames))\n",
    "print(\"Some example filenames:\", fnames[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newsgroups: comp.graphics\n",
      "Path: cantaloupe.srv.cs.cmu.edu!das-news.harvard.edu!noc.near.net!howland.reston.ans.net!agate!dog.ee.lbl.gov!network.ucsd.edu!usc!rpi!nason110.its.rpi.edu!mabusj\n",
      "From: mabusj@nason110.its.rpi.edu (Jasen M. Mabus)\n",
      "Subject: Looking for Brain in CAD\n",
      "Message-ID: <c285m+p@rpi.edu>\n",
      "Nntp-Posting-Host: nason110.its.rpi.edu\n",
      "Reply-To: mabusj@rpi.edu\n",
      "Organization: Rensselaer Polytechnic Institute, Troy, NY.\n",
      "Date: Thu, 29 Apr 1993 23:27:20 GMT\n",
      "Lines: 7\n",
      "\n",
      "Jasen Mabus\n",
      "RPI student\n",
      "\n",
      "\tI am looking for a hman brain in any CAD (.dxf,.cad,.iges,.cgm,etc.) or picture (.gif,.jpg,.ras,etc.) format for an animation demonstration. If any has or knows of a location please reply by e-mail to mabusj@rpi.edu.\n",
      "\n",
      "Thank you in advance,\n",
      "Jasen Mabus  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(open(data_dir / \"comp.graphics\" / \"38987\").read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there are header lines that are leaking the file's category, either explicitly (the first line is literally the category name), or implicitly, e.g. via the Organization filed. Let's get rid of the headers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing alt.atheism, 1000 files found\n",
      "Processing comp.graphics, 1000 files found\n",
      "Processing comp.os.ms-windows.misc, 1000 files found\n",
      "Processing comp.sys.ibm.pc.hardware, 1000 files found\n",
      "Processing comp.sys.mac.hardware, 1000 files found\n",
      "Processing comp.windows.x, 1000 files found\n",
      "Processing misc.forsale, 1000 files found\n",
      "Processing rec.autos, 1000 files found\n",
      "Processing rec.motorcycles, 1000 files found\n",
      "Processing rec.sport.baseball, 1000 files found\n",
      "Processing rec.sport.hockey, 1000 files found\n",
      "Processing sci.crypt, 1000 files found\n",
      "Processing sci.electronics, 1000 files found\n",
      "Processing sci.med, 1000 files found\n",
      "Processing sci.space, 1000 files found\n",
      "Processing soc.religion.christian, 997 files found\n",
      "Processing talk.politics.guns, 1000 files found\n",
      "Processing talk.politics.mideast, 1000 files found\n",
      "Processing talk.politics.misc, 1000 files found\n",
      "Processing talk.religion.misc, 1000 files found\n",
      "Classes: ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
      "Number of samples: 19997\n"
     ]
    }
   ],
   "source": [
    "samples = []\n",
    "labels = []\n",
    "class_names = []\n",
    "class_index = 0\n",
    "for dirname in sorted(os.listdir(data_dir)):\n",
    "    class_names.append(dirname)\n",
    "    dirpath = data_dir / dirname\n",
    "    fnames = os.listdir(dirpath)\n",
    "    print(\"Processing %s, %d files found\" % (dirname, len(fnames)))\n",
    "    for fname in fnames:\n",
    "        fpath = dirpath / fname\n",
    "        f = open(fpath, encoding=\"latin-1\")\n",
    "        content = f.read()\n",
    "        lines = content.split(\"\\n\")\n",
    "        lines = lines[10:]\n",
    "        content = \"\\n\".join(lines)\n",
    "        samples.append(content)\n",
    "        labels.append(class_index)\n",
    "    class_index += 1\n",
    "\n",
    "print(\"Classes:\", class_names)\n",
    "print(\"Number of samples:\", len(samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's actually one category that doesn't have the expected number of files, but the difference is small enough that the problem remains a balanced classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/Users/abasar/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe8db3a0e10>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(labels).value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle and split the data into training and test sets\n",
    "seed = 1337\n",
    "rng = np.random.RandomState(seed)\n",
    "rng.shuffle(samples)\n",
    "rng = np.random.RandomState(seed)\n",
    "rng.shuffle(labels)\n",
    "\n",
    "# Extract a training & validation split\n",
    "validation_split = 0.2\n",
    "num_validation_samples = int(validation_split * len(samples))\n",
    "train_samples = samples[:-num_validation_samples]\n",
    "val_samples = samples[-num_validation_samples:]\n",
    "train_labels = labels[:-num_validation_samples]\n",
    "val_labels = labels[-num_validation_samples:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a vocabulary index\n",
    "\n",
    "Let's use the TextVectorization to index the vocabulary found in the dataset. Later, we'll use the same layer instance to vectorize the samples.\n",
    "\n",
    "Our layer will only consider the top 20,000 words, and will truncate or pad sequences to be actually 200 tokens long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "vectorizer = TextVectorization(max_tokens=20000, output_sequence_length=200)\n",
    "text_ds = tf.data.Dataset.from_tensor_slices(train_samples).batch(128)\n",
    "vectorizer.adapt(text_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can retrieve the computed vocabulary used via vectorizer.get_vocabulary(). Let's print the top 5 words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '[UNK]', 'the', 'to', 'of', 'a', 'and', 'in', 'is', 'i', 'that', 'it', 'for', 'you', 'this', 'on', 'be', 'not', 'have', 'are', 'with', 'as', 'or', 'if', 'was', 'but', 'they', 'from', 'by', 'at', 'an', 'my', 'can', 'what', 'would', 'all', 'there', 'one', 'will', 'do', 'writes', 'about', 'we', 'he', 'has', 'so', 'your', 'article', 'no', 'any']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_vocabulary()[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's vectorize a test sentence:\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "This layer has basic options for managing text in a Keras model. It\n",
    "transforms a batch of strings (one sample = one string) into either a list of\n",
    "token indices (one sample = 1D tensor of integer token indices) or a dense\n",
    "representation (one sample = 1D tensor of float values representing data about\n",
    "the sample's tokens).\n",
    "\n",
    "If desired, the user can call this layer's adapt() method on a dataset.\n",
    "When this layer is adapted, it will analyze the dataset, determine the\n",
    "frequency of individual string values, and create a 'vocabulary' from them.\n",
    "This vocabulary can have unlimited size or be capped, depending on the\n",
    "configuration options for this layer; if there are more unique values in the\n",
    "input than the maximum vocabulary size, the most frequent terms will be used\n",
    "to create the vocabulary.\n",
    "\n",
    "The processing of each sample contains the following steps:\n",
    "\n",
    "  1. standardize each sample (usually lowercasing + punctuation stripping)\n",
    "  2. split each sample into substrings (usually words)\n",
    "  3. recombine substrings into tokens (usually ngrams)\n",
    "  4. index tokens (associate a unique int value with each token)\n",
    "  5. transform each sample using this index, either into a vector of ints or\n",
    "     a dense float vector.\n",
    "\n",
    "\n",
    "Attributes:\n",
    "  max_tokens: The maximum size of the vocabulary for this layer. If None,\n",
    "    there is no cap on the size of the vocabulary. Note that this vocabulary\n",
    "    contains 1 OOV token, so the effective number of tokens is `(max_tokens -\n",
    "    1 - (1 if output == \"int\" else 0))`.\n",
    "  standardize: Optional specification for standardization to apply to the\n",
    "    input text. Values can be None (no standardization),\n",
    "    'lower_and_strip_punctuation' (lowercase and remove punctuation) or a\n",
    "    Callable. Default is 'lower_and_strip_punctuation'.\n",
    "  split: Optional specification for splitting the input text. Values can be\n",
    "    None (no splitting), 'whitespace' (split on ASCII whitespace), or a\n",
    "    Callable. The default is 'whitespace'.\n",
    "  ngrams: Optional specification for ngrams to create from the possibly-split\n",
    "    input text. Values can be None, an integer or tuple of integers; passing\n",
    "    an integer will create ngrams up to that integer, and passing a tuple of\n",
    "    integers will create ngrams for the specified values in the tuple. Passing\n",
    "    None means that no ngrams will be created.\n",
    "  output_mode: Optional specification for the output of the layer. Values can\n",
    "    be \"int\", \"binary\", \"count\" or \"tf-idf\", configuring the layer as follows:\n",
    "      \"int\": Outputs integer indices, one integer index per split string\n",
    "        token. When output == \"int\", 0 is reserved for masked locations;\n",
    "        this reduces the vocab size to max_tokens-2 instead of max_tokens-1\n",
    "      \"binary\": Outputs a single int array per batch, of either vocab_size or\n",
    "        max_tokens size, containing 1s in all elements where the token mapped\n",
    "        to that index exists at least once in the batch item.\n",
    "      \"count\": As \"binary\", but the int array contains a count of the number\n",
    "        of times the token at that index appeared in the batch item.\n",
    "      \"tf-idf\": As \"binary\", but the TF-IDF algorithm is applied to find the\n",
    "        value in each token slot.\n",
    "  output_sequence_length: Only valid in INT mode. If set, the output will have\n",
    "    its time dimension padded or truncated to exactly `output_sequence_length`\n",
    "    values, resulting in a tensor of shape [batch_size,\n",
    "    output_sequence_length] regardless of how many tokens resulted from the\n",
    "    splitting step. Defaults to None.\n",
    "  pad_to_max_tokens: Only valid in  \"binary\", \"count\", and \"tf-idf\" modes. If\n",
    "    True, the output will have its feature axis padded to `max_tokens` even if\n",
    "    the number of unique tokens in the vocabulary is less than max_tokens,\n",
    "    resulting in a tensor of shape [batch_size, max_tokens] regardless of\n",
    "    vocabulary size. Defaults to True.\n",
    "\n",
    "Example:\n",
    "This example instantiates a TextVectorization layer that lowercases text,\n",
    "splits on whitespace, strips punctuation, and outputs integer vocab indices.\n",
    "\n",
    ">>> text_dataset = tf.data.Dataset.from_tensor_slices([\"foo\", \"bar\", \"baz\"])\n",
    ">>> max_features = 5000  # Maximum vocab size.\n",
    ">>> max_len = 4  # Sequence length to pad the outputs to.\n",
    ">>> embedding_dims = 2\n",
    ">>>\n",
    ">>> # Create the layer.\n",
    ">>> vectorize_layer = TextVectorization(\n",
    "...  max_tokens=max_features,\n",
    "...  output_mode='int',\n",
    "...  output_sequence_length=max_len)\n",
    ">>>\n",
    ">>> # Now that the vocab layer has been created, call `adapt` on the text-only\n",
    ">>> # dataset to create the vocabulary. You don't have to batch, but for large\n",
    ">>> # datasets this means we're not keeping spare copies of the dataset.\n",
    ">>> vectorize_layer.adapt(text_dataset.batch(64))\n",
    ">>>\n",
    ">>> # Create the model that uses the vectorize text layer\n",
    ">>> model = tf.keras.models.Sequential()\n",
    ">>>\n",
    ">>> # Start by creating an explicit input layer. It needs to have a shape of\n",
    ">>> # (1,) (because we need to guarantee that there is exactly one string\n",
    ">>> # input per batch), and the dtype needs to be 'string'.\n",
    ">>> model.add(tf.keras.Input(shape=(1,), dtype=tf.string))\n",
    ">>>\n",
    ">>> # The first layer in our model is the vectorization layer. After this\n",
    ">>> # layer, we have a tensor of shape (batch_size, max_len) containing vocab\n",
    ">>> # indices.\n",
    ">>> model.add(vectorize_layer)\n",
    ">>>\n",
    ">>> # Now, the model can map strings to integers, and you can add an embedding\n",
    ">>> # layer to map these integers to learned embeddings.\n",
    ">>> input_data = [[\"foo qux bar\"], [\"qux baz\"]]\n",
    ">>> model.predict(input_data)\n",
    "array([[2, 1, 4, 0],\n",
    "       [1, 3, 0, 0]])\n",
    "Call docstring:\n",
    "Wraps `call`, applying pre- and post-processing steps.\n",
    "\n",
    "Arguments:\n",
    "  *args: Positional arguments to be passed to `self.call`.\n",
    "  **kwargs: Keyword arguments to be passed to `self.call`.\n",
    "\n",
    "Returns:\n",
    "  Output tensor(s).\n",
    "\n",
    "Note:\n",
    "  - The following optional keyword arguments are reserved for specific uses:\n",
    "    * `training`: Boolean scalar tensor of Python boolean indicating\n",
    "      whether the `call` is meant for training or inference.\n",
    "    * `mask`: Boolean input mask.\n",
    "  - If the layer's `call` method takes a `mask` argument (as some Keras\n",
    "    layers do), its default value will be set to the mask generated\n",
    "    for `inputs` by the previous layer (if `input` did come from\n",
    "    a layer that generated a corresponding mask, i.e. if it came from\n",
    "    a Keras layer with masking support.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   2, 3697, 1686,   15,    2, 5943,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = vectorizer([[\"the cat sat on the mat\"]])\n",
    "output.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, \"the\" gets represented as \"2\". Why not 0, given that \"the\" was the first word in the vocabulary? That's because index 0 is reserved for padding and index 1 is reserved for \"out of vocabulary\" tokens.\n",
    "\n",
    "Here's a dict mapping words to their indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = vectorizer.get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we obtain the same encoding as above for our test sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3697, 1686, 15, 2, 5943]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [\"the\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"]\n",
    "[word_index[w] for w in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(voc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pre-trained word embeddings\n",
    "Let's download pre-trained GloVe embeddings (a 822M zip file).\n",
    "\n",
    "You'll need to run the following commands:\n",
    "\n",
    "```\n",
    "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!unzip -q glove.6B.zip\n",
    "```\n",
    "\n",
    "The archive contains text-encoded vectors of various sizes: 50-dimensional, 100-dimensional, 200-dimensional, 300-dimensional. We'll use the 100D ones.\n",
    "\n",
    "Let's make a dict mapping words (strings) to their NumPy vector representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "path_to_glove_file = os.path.join(\n",
    "    os.path.expanduser(\"~\"), \"data/glove.6B/glove.6B.100d.txt\"\n",
    ")\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(path_to_glove_file) as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's prepare a corresponding embedding matrix that we can use in a Keras Embedding layer. It's a simple NumPy matrix where entry at index i is the pre-trained vector for the word of index i in our vectorizer's vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.5985   , -0.46321  ,  0.13001  , -0.019576 ,  0.4603   ,\n",
       "       -0.3018   ,  0.8977   , -0.65634  ,  0.66858  , -0.49164  ,\n",
       "        0.037557 , -0.050889 ,  0.6451   , -0.53882  , -0.3765   ,\n",
       "       -0.04312  ,  0.51384  ,  0.17783  ,  0.28596  ,  0.92063  ,\n",
       "       -0.49349  , -0.48583  ,  0.61321  ,  0.78211  ,  0.19254  ,\n",
       "        0.91228  , -0.055596 , -0.12512  , -0.65688  ,  0.068557 ,\n",
       "        0.55629  ,  1.611    , -0.0073642, -0.48879  ,  0.45493  ,\n",
       "        0.96105  , -0.063369 ,  0.17432  ,  0.9814   , -1.3125   ,\n",
       "       -0.15801  , -0.54301  , -0.13888  , -0.26146  , -0.3691   ,\n",
       "        0.26844  , -0.24375  , -0.19484  ,  0.62583  , -0.7377   ,\n",
       "        0.38351  , -0.75004  , -0.39053  ,  0.091498 , -0.36591  ,\n",
       "       -1.4715   , -0.45228  ,  0.2256   ,  1.1412   , -0.38526  ,\n",
       "       -0.06716  ,  0.57288  , -0.39191  ,  0.31302  , -0.29235  ,\n",
       "       -0.96157  ,  0.15154  , -0.21659  ,  0.25103  ,  0.096967 ,\n",
       "        0.2843   ,  1.4296   , -0.50565  , -0.51374  , -0.47218  ,\n",
       "        0.32036  ,  0.023149 ,  0.22623  , -0.09725  ,  0.82126  ,\n",
       "        0.92599  , -1.0086   , -0.38639  ,  0.86408  , -1.206    ,\n",
       "       -0.28528  ,  0.2265   , -0.38773  ,  0.40879  ,  0.59303  ,\n",
       "        0.30769  ,  0.83804  , -0.63655  , -0.44639  , -0.43406  ,\n",
       "       -0.79364  , -0.28675  , -0.034398 ,  1.3431   ,  0.34904  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index[\"apple\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 20000)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_index.items()), len(voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 17999 words (2001 misses)\n"
     ]
    }
   ],
   "source": [
    "num_tokens = len(voc)+2\n",
    "embedding_dim = 100\n",
    "hits = 0\n",
    "misses = 0\n",
    "missing_words = []\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        missing_words.append(word)\n",
    "        misses += 1\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '[UNK]', 'maxaxaxaxaxaxaxaxaxaxaxaxaxaxax', 'nntppostinghost', 'youve', 'xnewsreader', 'shouldnt', 'replyto', 'os2', 'christianaramisrutgersedu', 'odwyer', 'inreplyto', 'xterm', 'imho', 'x11r5', 'werent', 'messageid', 'theyve', 'openwindows', 'theyll', 'frankd012s658uucp', 'xsoviet', 'msdos', 'argic', 'vaxvms', 'scsi2', 'clh', '24bit', 'thanx', '8bit', 'sternlight', 'oname', 'sandviknewtonapplecom', 'theyd', 'newssoftware', 'vnews', 'ohanus', 'appressian', 'xview', 'x11r4', 'tcpip', 'followupto', 'scsi1', '32bit', 'v32bis', 'koreshs', 'hadnt', 'cobbalexialisuiucedu', 'itll', 'colormap', 'hicnet', 'phigs', 'exportlcsmitedu', 'altatheism', 'xwindows', 'pl8', 'liveseysolntzewpdsgicom', 'henryzootorontoedu', 'xdm', 'ripem', 'scicrypt', 'contrib', 'crameroptilinkcom', 'hallambaker', 'mathewmantiscouk', 'c650', 'mswindows', 'configsys', 'scispace', 'odwyersseie', 'noknock', 'lciii', 'hisher', 'eofnotok', 'ksand', 'jakebony1bonycom', 'cdtvosstratuscom', 'cdtrocketswstratuscom', 'alink', 'xdisclaimer', 'accessdigexnet', 'strnlghtnetcomcom', 'pixmap', 'maynardramseycslaurentianca', 'archivename', 'rayshade', 'xuseragent', 'solntzewpdsgicom', 'nuntius', 'fprintfstderr', 'arromdee', 'rocketswstratuscom', 'n3jxp', 'pl9', 'oreilly', 'olwm', 'selfdefense', 'harddisk', 'gebcadredslpittedu', '16bit']\n"
     ]
    }
   ],
   "source": [
    "print(missing_words[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load the pre-trained word embeddings matrix into an Embedding layer.\n",
    "\n",
    "Note that we set trainable=False so as to keep the embeddings fixed (we don't want to update them during training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "embedding_layer = Embedding(\n",
    "    num_tokens,\n",
    "    embedding_dim,\n",
    "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "    trainable=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model\n",
    "A simple 1D convnet with global max pooling and a classifier at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_10 (Embedding)     (None, None, 100)         2000200   \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, None, 128)         64128     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, None, 128)         82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, None, 128)         82048     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 20)                2580      \n",
      "=================================================================\n",
      "Total params: 2,247,516\n",
      "Trainable params: 247,316\n",
      "Non-trainable params: 2,000,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "int_sequences_input = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "embedded_sequences = embedding_layer(int_sequences_input)\n",
    "x = layers.Conv1D(filters = 128, kernel_size= 5, activation=\"relu\")(embedded_sequences)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(filters=128, kernel_size=5, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(128, 5, activation=\"relu\")(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "preds = layers.Dense(len(class_names), activation=\"softmax\")(x)\n",
    "model = keras.Model(inputs = int_sequences_input, ouputs = preds)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model\n",
    "First, convert our list-of-strings data to NumPy arrays of integer indices. The arrays are right-padded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vectorizer(np.array([[s] for s in train_samples])).numpy()\n",
    "x_val = vectorizer(np.array([[s] for s in val_samples])).numpy()\n",
    "\n",
    "y_train = np.array(train_labels)\n",
    "y_val = np.array(val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use categorical crossentropy as our loss since we're doing softmax classification. Moreover, we use sparse_categorical_crossentropy since our labels are integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "125/125 [==============================] - 8s 67ms/step - loss: 2.6963 - acc: 0.1374 - val_loss: 2.1628 - val_acc: 0.2671\n",
      "Epoch 2/20\n",
      "125/125 [==============================] - 8s 65ms/step - loss: 1.9632 - acc: 0.3179 - val_loss: 1.7915 - val_acc: 0.3818\n",
      "Epoch 3/20\n",
      "125/125 [==============================] - 9s 70ms/step - loss: 1.5442 - acc: 0.4696 - val_loss: 1.3383 - val_acc: 0.5461\n",
      "Epoch 4/20\n",
      "125/125 [==============================] - 9s 71ms/step - loss: 1.2849 - acc: 0.5564 - val_loss: 1.2864 - val_acc: 0.5614\n",
      "Epoch 5/20\n",
      "125/125 [==============================] - 9s 73ms/step - loss: 1.1251 - acc: 0.6136 - val_loss: 1.1891 - val_acc: 0.6089\n",
      "Epoch 6/20\n",
      "125/125 [==============================] - 9s 74ms/step - loss: 1.0020 - acc: 0.6533 - val_loss: 1.0779 - val_acc: 0.6309\n",
      "Epoch 7/20\n",
      "125/125 [==============================] - 9s 75ms/step - loss: 0.8882 - acc: 0.6911 - val_loss: 1.0416 - val_acc: 0.6559\n",
      "Epoch 8/20\n",
      "125/125 [==============================] - 10s 81ms/step - loss: 0.7872 - acc: 0.7273 - val_loss: 1.0980 - val_acc: 0.6449\n",
      "Epoch 9/20\n",
      "125/125 [==============================] - 10s 80ms/step - loss: 0.6919 - acc: 0.7595 - val_loss: 1.0301 - val_acc: 0.6707\n",
      "Epoch 10/20\n",
      "125/125 [==============================] - 12s 94ms/step - loss: 0.6142 - acc: 0.7823 - val_loss: 1.0845 - val_acc: 0.6722\n",
      "Epoch 11/20\n",
      "125/125 [==============================] - 17s 134ms/step - loss: 0.5309 - acc: 0.8137 - val_loss: 1.6721 - val_acc: 0.5614\n",
      "Epoch 12/20\n",
      "125/125 [==============================] - 20s 163ms/step - loss: 0.4687 - acc: 0.8331 - val_loss: 1.1986 - val_acc: 0.6689\n",
      "Epoch 13/20\n",
      "125/125 [==============================] - 15s 121ms/step - loss: 0.4023 - acc: 0.8575 - val_loss: 1.2134 - val_acc: 0.6774\n",
      "Epoch 14/20\n",
      "125/125 [==============================] - 12s 97ms/step - loss: 0.3604 - acc: 0.8734 - val_loss: 1.2331 - val_acc: 0.6714\n",
      "Epoch 15/20\n",
      "125/125 [==============================] - 11s 91ms/step - loss: 0.3090 - acc: 0.8910 - val_loss: 1.1562 - val_acc: 0.7029\n",
      "Epoch 16/20\n",
      "125/125 [==============================] - 11s 86ms/step - loss: 0.2746 - acc: 0.9049 - val_loss: 1.3353 - val_acc: 0.6857\n",
      "Epoch 17/20\n",
      "125/125 [==============================] - 11s 85ms/step - loss: 0.2448 - acc: 0.9194 - val_loss: 1.3590 - val_acc: 0.6964\n",
      "Epoch 18/20\n",
      "125/125 [==============================] - 10s 82ms/step - loss: 0.2301 - acc: 0.9214 - val_loss: 1.4272 - val_acc: 0.6782\n",
      "Epoch 19/20\n",
      "125/125 [==============================] - 10s 83ms/step - loss: 0.2062 - acc: 0.9297 - val_loss: 1.4395 - val_acc: 0.6962\n",
      "Epoch 20/20\n",
      "125/125 [==============================] - 10s 82ms/step - loss: 0.1995 - acc: 0.9348 - val_loss: 1.5405 - val_acc: 0.6854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe8cfc1d290>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"]\n",
    ")\n",
    "model.fit(x_train, \n",
    "          y_train, \n",
    "          batch_size=128, \n",
    "          epochs=20, \n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export an end-to-end model\n",
    "Now, we may want to export a Model object that takes as input a string of arbitrary length, rather than a sequence of indices. It would make the model much more portable, since you wouldn't have to worry about the input preprocessing pipeline.\n",
    "\n",
    "Our vectorizer is actually a Keras layer, so it's simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe5ea455f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array(['comp.graphics', 'talk.politics.guns'], dtype='<U24'),\n",
       " array([[8.6163065e-14, 1.0000000e+00, 8.1667971e-11, 5.0409850e-11,\n",
       "         1.0017644e-14, 1.2687408e-09, 1.4871375e-10, 6.3082312e-20,\n",
       "         6.7328045e-19, 4.3720151e-14, 2.5983481e-15, 3.3139664e-17,\n",
       "         6.2604913e-12, 1.4900717e-12, 1.8316663e-12, 3.3479581e-16,\n",
       "         1.2898839e-20, 1.6031135e-13, 4.0155327e-17, 5.8855179e-16],\n",
       "        [4.5647793e-03, 1.7558691e-03, 3.9794748e-03, 2.7834221e-03,\n",
       "         6.4468294e-02, 2.4134570e-03, 6.5766804e-02, 1.1867763e-01,\n",
       "         1.2352383e-02, 9.6610619e-04, 2.1310020e-03, 8.6450361e-02,\n",
       "         8.9930385e-02, 1.8017642e-02, 1.6330630e-02, 2.3955648e-04,\n",
       "         3.2766905e-01, 7.9255141e-03, 1.5451580e-01, 1.9061811e-02]],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_input = keras.Input(shape=(1,), dtype=\"string\")\n",
    "x = vectorizer(string_input)\n",
    "preds = model(x)\n",
    "end_to_end_model = keras.Model(string_input, preds)\n",
    "\n",
    "probabilities = end_to_end_model.predict([\n",
    "        [\"This message is about computer graphics and 3D modeling\"],\n",
    "        [\"Formed in 1972, Van Halen went on to sell more than 56 million albums in the United States alone.\"]\n",
    "])\n",
    "\n",
    "np.array(class_names)[np.argmax(probabilities, axis = 1)], probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe5ed307ef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1, 128),\n",
       " array([[1.0283028 , 0.58883107, 0.34627348, 0.45366755, 0.39792728,\n",
       "         1.6240157 , 0.35595304, 0.5811593 , 0.68176633, 0.45190126,\n",
       "         1.6052558 , 0.92403984, 1.0534039 , 1.0050759 , 0.23602894,\n",
       "         0.11412469, 1.497736  , 1.0623947 , 1.0635756 , 0.15405472,\n",
       "         1.1795343 , 0.5973297 , 0.12623766, 0.5315096 , 0.64895576,\n",
       "         0.18070003, 0.2940896 , 0.01992673, 0.56502604, 0.41143757,\n",
       "         0.828557  , 0.15629146, 0.14446266, 0.5084504 , 1.0018342 ,\n",
       "         0.38307387, 0.7768181 , 1.1129724 , 0.55157644, 0.49135196,\n",
       "         1.0584311 , 0.9648414 , 0.7982595 , 1.1589749 , 1.1127363 ,\n",
       "         0.7202855 , 0.63853395, 0.35307026, 0.4354219 , 1.266166  ,\n",
       "         0.49852836, 0.17972006, 0.86601204, 0.9140568 , 0.917071  ,\n",
       "         1.120836  , 0.22844522, 0.9214363 , 0.53205425, 0.01647147,\n",
       "         0.84797764, 0.22623473, 0.6193829 , 1.1286234 , 0.        ,\n",
       "         0.45299557, 0.29508665, 0.03716601, 0.00653753, 0.59399354,\n",
       "         0.6199873 , 1.0038533 , 0.5884161 , 0.53954464, 0.5389154 ,\n",
       "         0.58810073, 0.24147028, 0.50963914, 0.49017057, 0.6529326 ,\n",
       "         1.0539992 , 0.6427243 , 0.7984701 , 1.0614915 , 0.2578517 ,\n",
       "         0.29165268, 0.6989551 , 0.8221884 , 0.6574644 , 0.52470165,\n",
       "         0.9682709 , 0.7142507 , 0.54886174, 1.1904557 , 1.3348347 ,\n",
       "         0.5337431 , 0.01206443, 0.59089184, 0.5988455 , 0.64825225,\n",
       "         0.6997706 , 1.418257  , 1.298702  , 0.33229747, 0.7696154 ,\n",
       "         0.7019222 , 0.8607837 , 1.0171309 , 0.91570675, 0.5403948 ,\n",
       "         0.7973942 , 0.37345773, 1.6562972 , 0.        , 0.38429004,\n",
       "         1.0047808 , 1.3608816 , 1.1706743 , 0.55572337, 0.        ,\n",
       "         0.0100092 , 0.6584195 , 0.66775113, 0.78041834, 1.2997035 ,\n",
       "         0.25094914, 0.25675347, 0.2390143 ]], dtype=float32))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "a = (keras \n",
    "    .Model(string_input, embedding_layer(vectorizer(string_input))) \n",
    "    .predict([[\"this message is about computer graphics and 3D modeling\"]]))\n",
    "a.shape\n",
    "\"\"\"\n",
    "\n",
    "a = keras.Sequential([\n",
    "    keras.Input(shape=(None,), dtype=\"string\"),\n",
    "    vectorizer,\n",
    "    embedding_layer,\n",
    "    layers.Conv1D(filters = 128, kernel_size= 5, activation=\"relu\"),\n",
    "    layers.GlobalMaxPooling1D()\n",
    "]).predict([\n",
    "        [\"Formed in 1972, Van Halen went on to sell more than 56 million albums in the United States alone.\"]\n",
    "])\n",
    "a.shape, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
